{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgbm\n",
    "# import optuna.integration.lightgbm as lgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import average_precision_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.set_option('display.max_Columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_time_series = False\n",
    "is_ensumble = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../input/'\n",
    "OUTPUT_DIR = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feather(filename):\n",
    "    df = pd.read_feather(os.path.join(INPUT_DIR, filename))\n",
    "    print(filename, df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.f (1997595, 35)\n",
      "test.f (390095, 30)\n"
     ]
    }
   ],
   "source": [
    "train_df = read_feather('train.f')\n",
    "test_df = read_feather('test.f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign.f (14627, 4)\n",
      "map_game_feed_native_video_assets.f (2796, 3)\n",
      "advertiser_video.f (11707, 6)\n",
      "advertiser_converted_video.f (198622, 8)\n"
     ]
    }
   ],
   "source": [
    "campaign_df = read_feather('campaign.f')\n",
    "map_gv_df = read_feather('map_game_feed_native_video_assets.f')\n",
    "ad_video_df = read_feather('advertiser_video.f')\n",
    "ad_cvideo_df = read_feather('advertiser_converted_video.f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_cvideo_df (107493, 8)\n"
     ]
    }
   ],
   "source": [
    "ad_cvideo_df = ad_cvideo_df.drop_duplicates(\n",
    "    subset=['mst_advertiser_video_id', \n",
    "                   'mst_game_feed_id', \n",
    "                    'mst_video_template_id'], keep='last')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['vertical', 'horizontal'])\n",
    "ad_cvideo_df['rectangle_type_id'] = le.transform(ad_cvideo_df['rectangle_type'])\n",
    "ad_cvideo_df.drop(columns=['rectangle_type'], inplace=True)\n",
    "print('ad_cvideo_df', ad_cvideo_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map_game_feed_native_video_assetsをマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_gamefeed_features(input_df):\n",
    "    input_merge = pd.merge(input_df, map_gv_df, \n",
    "                           left_on='game_feed_id', right_on='mst_game_feed_id', how='left').drop(columns=['mst_game_feed_id'])\n",
    "    \n",
    "    horizontal = ad_video_df.copy()\n",
    "    left_keys = ['horizontal_mst_advertiser_video_id', 'advertiser_id']\n",
    "    right_keys = ['id', 'mst_advertiser_id']\n",
    "    horizontal.columns = [f'horizontal_{c}' if c not in right_keys else c for c in horizontal.columns]\n",
    "    input_merge = pd.merge(input_merge, horizontal, left_on=left_keys, right_on=right_keys, how='left').drop(columns=right_keys) \n",
    "    \n",
    "    vertical = ad_video_df.copy()\n",
    "    left_keys = ['vertical_mst_advertiser_video_id', 'advertiser_id']\n",
    "    right_keys = ['id', 'mst_advertiser_id']\n",
    "    vertical.columns = [f'vertical_{c}' if c not in right_keys else c for c in vertical.columns]\n",
    "    input_merge = pd.merge(input_merge, vertical, left_on=left_keys, right_on=right_keys, how='left').drop(columns=right_keys)\n",
    "    \n",
    "    left_keys = [\n",
    "        \"horizontal_mst_advertiser_video_id\",\n",
    "        \"game_feed_id\",\n",
    "        \"video_template_id\",\n",
    "    ]\n",
    "    right_keys = [\n",
    "        \"mst_advertiser_video_id\",\n",
    "        \"mst_game_feed_id\",\n",
    "        \"mst_video_template_id\",\n",
    "    ]\n",
    "    horizontal = ad_cvideo_df.copy()\n",
    "    horizontal.columns = [f\"horizontal_converted_{c}\" if c not in right_keys else c for c in horizontal.columns]\n",
    "    input_merge = pd.merge(input_merge, horizontal, left_on=left_keys, right_on=right_keys, how='left').drop(columns=right_keys) \n",
    "    \n",
    "    left_keys = [\n",
    "        \"vertical_mst_advertiser_video_id\",\n",
    "        \"game_feed_id\",\n",
    "        \"video_template_id\",\n",
    "    ]\n",
    "    right_keys = [\n",
    "        \"mst_advertiser_video_id\",\n",
    "        \"mst_game_feed_id\",\n",
    "        \"mst_video_template_id\",\n",
    "    ]\n",
    "    vertical = ad_cvideo_df.copy()\n",
    "    vertical.columns = [f\"vertical_converted_{c}\" if c not in right_keys else c for c in vertical.columns]\n",
    "    input_merge = pd.merge(input_merge, vertical, left_on=left_keys, right_on=right_keys, how='left').drop(columns=right_keys)\n",
    "    \n",
    "#     input_merge.drop(columns=['game_feed_id', 'advertiser_id', 'video_template_id', \n",
    "#                               'horizontal_mst_advertiser_video_id', 'vertical_mst_advertiser_video_id'], inplace=True)\n",
    "    \n",
    "    # merge\n",
    "    merge_col = ['duration', 'file_size', 'converted_file_size', 'converted_bitrate']\n",
    "    vert_horz = ['vertical_', 'horizontal_']\n",
    "    \n",
    "    for m_col in merge_col:\n",
    "        input_merge[m_col] = 0\n",
    "        for vh in vert_horz:\n",
    "            input_merge[m_col] = input_merge[m_col] + input_merge[vh+m_col].fillna(0)\n",
    "            input_merge.drop(columns=[vh+m_col], inplace=True)\n",
    "    \n",
    "    return input_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### campaignをマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_campaign_features(input_df):\n",
    "    campaign = pd.merge(input_df, campaign_df, left_on='campaign_id', right_on='id', how='left')\n",
    "    campaign.drop(columns=['id'], inplace=True)\n",
    "    return campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(input_df):\n",
    "    input_df = merge_gamefeed_features(input_df)\n",
    "    input_df = merge_campaign_features(input_df)\n",
    "    print('merge', input_df.shape)\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df (1997595, 35)\n",
      "merge (1997595, 54)\n",
      "test_df (390095, 30)\n",
      "merge (390095, 49)\n"
     ]
    }
   ],
   "source": [
    "print('train_df', train_df.shape)\n",
    "train_df = merge_all(train_df)\n",
    "print('test_df', test_df.shape)\n",
    "test_df = merge_all(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_df (2387690, 54)\n"
     ]
    }
   ],
   "source": [
    "whole_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print('whole_df', whole_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_col = [\n",
    "    'adspot_id',\n",
    "    'adspot_video_format_id', \n",
    "    'country_code', \n",
    "    'game_feed_asset_type_id',\n",
    "    'item_id', \n",
    "    'os', \n",
    "    'video_template_id',\n",
    "    'uid',\n",
    "#     'auction_type_id', ->OHE\n",
    "#     'user_type_id',  ->OHE\n",
    "    \n",
    "#     'advertiser_id',  ->TGE\n",
    "#     'app_id',   ->TGE\n",
    "#     'media_app_id',   ->TGE\n",
    "#     'campaign_id',  ->TGE\n",
    "    'category_id', \n",
    "    'game_feed_id', \n",
    "    'game_template_id',\n",
    "    \n",
    "    'horizontal_mst_advertiser_video_id',\n",
    "    'vertical_mst_advertiser_video_id', \n",
    "    'horizontal_converted_rectangle_type_id', \n",
    "    'vertical_converted_rectangle_type_id',\n",
    "    'mst_advertiser_id', \n",
    "    'mst_advertiser_order_id', \n",
    "    'mst_user_type_id',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_enc_col = [\n",
    "#     'advertiser_id', \n",
    "    'app_id', \n",
    "    'media_app_id', \n",
    "    'campaign_id',\n",
    "#     'category_id',\n",
    "#     'game_feed_id',\n",
    "#     'game_template_id',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_enc_col = [\n",
    "    'advertiser_id', \n",
    "    'adnw_id', \n",
    "    'adspot_id',\n",
    "    'category_id', \n",
    "    'game_feed_id',\n",
    "    'uid', \n",
    "    'game_template_id',\n",
    "    \n",
    "    'mst_advertiser_order_id', \n",
    "    'mst_user_type_id',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_enc_col = [\n",
    "    'auction_type_id',\n",
    "    'header_bidding',\n",
    "    'is_interstitial',\n",
    "    'user_type_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_col = [\n",
    "    'first_login_interval',\n",
    "    'max_login_interval', \n",
    "    'frequency', \n",
    "    'login_frequency', \n",
    "    'last_login_interval',\n",
    "    'from_click',\n",
    "    'pos',\n",
    "#     'adnw_id',\n",
    "#     'header_bidding', \n",
    "#     'is_interstitial'\n",
    "    \n",
    "    'horizontal_width',\n",
    "    'horizontal_height', \n",
    "    'vertical_width', \n",
    "    'vertical_height',\n",
    "    'horizontal_converted_width', \n",
    "    'horizontal_converted_height',\n",
    "    'vertical_converted_width',\n",
    "    'vertical_converted_height', \n",
    "    'duration', \n",
    "    'file_size', \n",
    "    'converted_file_size', \n",
    "    'converted_bitrate',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_overlapping(column: str):\n",
    "    \"\"\"train/testにしか出てこない値を調べる\"\"\"\n",
    "    only_in_train = set(train_df[column].unique()) - set(test_df[column].unique())\n",
    "    only_in_test = set(test_df[column].unique()) - set(train_df[column].unique())\n",
    "    non_overlapping = only_in_train.union(only_in_test)\n",
    "    return non_overlapping\n",
    "\n",
    "def category2num(input_df, columns: list):\n",
    "    input_ = input_df[columns].copy()\n",
    "    for column in columns:\n",
    "        non_overlapping = get_non_overlapping(column)\n",
    "        if input_df[column].dtype == np.dtype(\"O\"):\n",
    "            # dtypeがobjectなら欠損は'missing' クラスにする\n",
    "            input_[column] = input_df[column].fillna(\"missing\")\n",
    "            input_[column] = input_[column].map(lambda x: x if x not in non_overlapping else \"other\")\n",
    "        else:\n",
    "            # dtypeがint/floatなら欠損は'-1'とする\n",
    "            input_[column] = input_df[column].fillna(-1)\n",
    "            input_[column] = input_[column].map(lambda x: x if x not in non_overlapping else -2)\n",
    "\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_LE (1997595, 18)\n",
      "test_LE (390095, 18)\n"
     ]
    }
   ],
   "source": [
    "train_LE = category2num(train_df, label_encoding_col)\n",
    "print('train_LE', train_LE.shape)\n",
    "test_LE = category2num(test_df, label_encoding_col)\n",
    "print('test_LE', test_LE.shape)\n",
    "concatenated = pd.concat([train_LE, test_LE], axis=0).reset_index(drop=True)\n",
    "\n",
    "for column in label_encoding_col:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(concatenated[column])\n",
    "    train_LE[column] = le.transform(train_LE[column])\n",
    "    test_LE[column] = le.transform(test_LE[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_encoding_features(input_df, is_test=False):\n",
    "    if is_test:\n",
    "        return test_LE\n",
    "    else:\n",
    "        return train_LE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(train, test, enc_col):\n",
    "    group_train = train.groupby([enc_col]).mean()[['target']].reset_index()\n",
    "    test_copy = test[[enc_col]].copy()\n",
    "    test_merge = pd.merge(test_copy, group_train, on=[enc_col], how='left')\n",
    "    test_merge.set_index(test_copy.index, inplace=True)\n",
    "    test_merge['target'].fillna(train['target'].mean(), inplace=True)\n",
    "    enc_name = 'TGE_' + enc_col\n",
    "    test_merge.rename(columns={'target': enc_name}, inplace=True)\n",
    "    return test_merge.drop(columns=enc_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_targetencoding_features(input_df, is_test=False):\n",
    "    \n",
    "    if is_test:\n",
    "        # test用 (全データ使用)\n",
    "        print('TGE for test')\n",
    "        tgt_all = pd.DataFrame()\n",
    "        for enc_col in target_enc_col:\n",
    "            tmp = target_encoding(train_df, test_df, enc_col)\n",
    "            tgt_all = pd.concat([tgt_all, tmp], axis=1)\n",
    "        return tgt_all\n",
    "    \n",
    "    else:\n",
    "        # train用 (oof)\n",
    "        print('TGE for train (TimeSeriesSplit)')\n",
    "#         kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        kf = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "        tgt_all = pd.DataFrame()\n",
    "        for enc_col in target_enc_col:\n",
    "            tgt_col = pd.DataFrame()\n",
    "\n",
    "            for train_index, eval_index in kf.split(train_df):\n",
    "                kf_train = train_df.iloc[train_index]\n",
    "                kf_eval = train_df.iloc[eval_index]\n",
    "\n",
    "                tmp = target_encoding(kf_train, kf_eval, enc_col)\n",
    "                tgt_col = pd.concat([tgt_col, tmp])\n",
    "\n",
    "            tgt_all = pd.concat([tgt_all, tgt_col], axis=1)\n",
    "            print(enc_col)\n",
    "        \n",
    "        return tgt_all.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_encoding_features(input_df, is_test=False):\n",
    "    out_df = pd.DataFrame()\n",
    "    for c in count_enc_col:\n",
    "        series = whole_df[c]\n",
    "        vc = series.value_counts(dropna=False)\n",
    "\n",
    "        _df = pd.DataFrame(input_df[c].map(vc))\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "\n",
    "    out_df = out_df.add_prefix('CE_')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot_encoding_features(input_df, is_test=False):\n",
    "    out_df = pd.DataFrame()\n",
    "    for c in onehot_enc_col:\n",
    "        series = input_df[c]\n",
    "        cat = pd.Categorical(series, categories=whole_df[c].dropna().unique())\n",
    "        _df = pd.get_dummies(cat)\n",
    "        _df.columns = _df.columns.tolist()\n",
    "        _df = _df.add_prefix(c + '=')\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "\n",
    "    return out_df.add_prefix('OH_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集約系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregate_features(input_df, is_test=False):\n",
    "    return _run_aggregation(input_df, 'uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_aggregation(input_df, agg_column):\n",
    "    _agg_df = pd.concat([\n",
    "#         whole_df.groupby(agg_column)['last_login_interval'].agg(['mean']).add_prefix('last_login_int_'),\n",
    "#         whole_df.groupby(agg_column)['first_login_interval'].agg(['mean']).add_prefix('first_login_int_'),\n",
    "#         whole_df.groupby(agg_column)['max_login_interval'].agg(['mean']).add_prefix('max_login_int_'),\n",
    "#         whole_df.groupby(agg_column)['frequency'].agg(['mean']).add_prefix('frequency_'),\n",
    "#         whole_df.groupby(agg_column)['login_frequency'].agg(['mean']).add_prefix('login_frequency_'),\n",
    "        \n",
    "        whole_df.groupby(agg_column)['advertiser_id'].nunique(),\n",
    "        whole_df.groupby(agg_column)['app_id'].nunique(),\n",
    "        whole_df.groupby(agg_column)['media_app_id'].nunique(),\n",
    "        whole_df.groupby(agg_column)['campaign_id'].nunique()\n",
    "    ], axis=1)\n",
    "\n",
    "    out_df = pd.merge(input_df[agg_column], _agg_df, on=agg_column, how='left')\n",
    "    out_df = out_df.drop(columns=agg_column).add_suffix('_by_{}'.format(agg_column))\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四則演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_operation(input_df):\n",
    "#     input_df['first_last_login_interval'] = input_df['first_login_interval'] - input_df['last_login_interval']\n",
    "#     input_df['login_freq_frequency'] = input_df['login_frequency'] - input_df['frequency']\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 連続変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_features(input_df, is_test=False):\n",
    "    return input_df[continuous_col].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(input_df, is_test=False):\n",
    "    date_df = pd.DataFrame(pd.to_datetime(input_df['imp_at'], utc=True))\n",
    "    date_df['imp_at'] = date_df['imp_at'].dt.tz_convert('Asia/Tokyo')\n",
    "#     date_df['day'] = date_df['imp_at'].dt.day\n",
    "    date_df['hour'] = date_df['imp_at'].dt.hour\n",
    "#     date_df['total_minute'] = date_df['imp_at'].dt.hour*60+date_df['imp_at'].dt.minute\n",
    "    date_df['hour_zone'] = pd.cut(date_df['hour'].values, bins=[-np.inf, 6, 12, 18, np.inf]).codes\n",
    "    date_df['dayofweek'] = date_df['imp_at'].dt.dayofweek\n",
    "    date_df.drop(columns=['imp_at'], inplace=True)\n",
    "    return date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_whole_imp_at_feature() -> pd.DataFrame:\n",
    "    \"\"\"impression が起こった時刻が dayofweek / hour_zone の意味でどれだけ偏っているか集計した data-frame を作成する\"\"\"\n",
    "\n",
    "    imp_at = pd.to_datetime(whole_df['imp_at']) + timedelta(hours=9) # utc -> asia/tokyo\n",
    "    out_df = pd.DataFrame()\n",
    "    out_df['hours'] = imp_at.dt.hour\n",
    "    out_df['dayofweek'] = imp_at.dt.dayofweek\n",
    "    out_df['hour_zone'] = pd.cut(out_df['hours'].values, bins=[-np.inf, 6, 12, 18, np.inf]).codes\n",
    "\n",
    "    def _create_pivot(input_df, c, column='dayofweek', values='hours'):\n",
    "        _df = pd.pivot_table(data=input_df, index=[c], columns=[column], values=values, aggfunc='count')\n",
    "        _df = _df.fillna(0)\n",
    "        _df.columns = [column + '=' + str(x) for x in _df.columns]\n",
    "\n",
    "        # index ごとに正規化して割合にする\n",
    "        _df = _df.div(_df.sum(axis=1), axis=0)\n",
    "        return pd.merge(input_df[c], _df, on=c, how='left').drop(columns=[c]).add_prefix(c + '_')\n",
    "\n",
    "    # uid での集約\n",
    "    for c in ['uid']:\n",
    "        _df = out_df.copy()\n",
    "        _df[c] = whole_df[c]\n",
    "        _feat = pd.concat([\n",
    "            _create_pivot(_df, c),\n",
    "            _create_pivot(_df, c, column='hour_zone', values='dayofweek')  \n",
    "        ], axis=1)\n",
    "        out_df = pd.concat([out_df, _feat], axis=1)\n",
    "\n",
    "    out_df['request_id'] = whole_df['request_id']\n",
    "    out_df.drop(columns=['hours', 'dayofweek', 'hour_zone'], inplace=True)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_whole_df = _create_whole_imp_at_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imp_at_agg_features(input_df, is_test=False):\n",
    "    return pd.merge(input_df['request_id'], datetime_whole_df, on='request_id', how='left').drop(columns=['request_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [\n",
    "    create_continuous_features,\n",
    "    create_label_encoding_features,\n",
    "    create_date_features,\n",
    "    create_targetencoding_features,\n",
    "    create_count_encoding_features,\n",
    "    create_onehot_encoding_features,\n",
    "    create_aggregate_features,\n",
    "    create_imp_at_agg_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature(input_df, is_test=False):\n",
    "    out_df = pd.DataFrame()\n",
    "    for func in processors:\n",
    "        _df = func(input_df, is_test)\n",
    "#         assert len(_df) == len(input_df), func.__name__\n",
    "        out_df = pd.concat([out_df, _df], axis=1)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGE for train (TimeSeriesSplit)\n",
      "app_id\n",
      "media_app_id\n",
      "campaign_id\n",
      "TGE for test\n"
     ]
    }
   ],
   "source": [
    "train_feat_df = to_feature(train_df)\n",
    "test_feat_df = to_feature(test_df, True)\n",
    "train_feat_df = feature_operation(train_feat_df)\n",
    "test_feat_df = feature_operation(test_feat_df)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feat_df (1997595, 78)\n",
      "test_feat_df (390095, 78)\n"
     ]
    }
   ],
   "source": [
    "train_feat_df = pd.read_feather('../input/train_feat_df.f')\n",
    "test_feat_df = pd.read_feather('../input/test_feat_df.f')\n",
    "print('train_feat_df', train_feat_df.shape)\n",
    "print('test_feat_df', test_feat_df.shape)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_feat_df) == len(train_df)\n",
    "assert len(test_feat_df) == len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "feature_count = len(train_feat_df.columns)\n",
    "print(feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_login_interval</th>\n",
       "      <th>max_login_interval</th>\n",
       "      <th>frequency</th>\n",
       "      <th>login_frequency</th>\n",
       "      <th>last_login_interval</th>\n",
       "      <th>from_click</th>\n",
       "      <th>pos</th>\n",
       "      <th>horizontal_width</th>\n",
       "      <th>horizontal_height</th>\n",
       "      <th>vertical_width</th>\n",
       "      <th>vertical_height</th>\n",
       "      <th>horizontal_converted_width</th>\n",
       "      <th>horizontal_converted_height</th>\n",
       "      <th>vertical_converted_width</th>\n",
       "      <th>vertical_converted_height</th>\n",
       "      <th>duration</th>\n",
       "      <th>file_size</th>\n",
       "      <th>converted_file_size</th>\n",
       "      <th>converted_bitrate</th>\n",
       "      <th>adspot_id</th>\n",
       "      <th>adspot_video_format_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>game_feed_asset_type_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>os</th>\n",
       "      <th>video_template_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>category_id</th>\n",
       "      <th>game_feed_id</th>\n",
       "      <th>game_template_id</th>\n",
       "      <th>horizontal_mst_advertiser_video_id</th>\n",
       "      <th>vertical_mst_advertiser_video_id</th>\n",
       "      <th>horizontal_converted_rectangle_type_id</th>\n",
       "      <th>vertical_converted_rectangle_type_id</th>\n",
       "      <th>mst_advertiser_id</th>\n",
       "      <th>mst_advertiser_order_id</th>\n",
       "      <th>mst_user_type_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_zone</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>TGE_app_id</th>\n",
       "      <th>TGE_media_app_id</th>\n",
       "      <th>TGE_campaign_id</th>\n",
       "      <th>CE_advertiser_id</th>\n",
       "      <th>CE_adnw_id</th>\n",
       "      <th>CE_adspot_id</th>\n",
       "      <th>CE_category_id</th>\n",
       "      <th>CE_game_feed_id</th>\n",
       "      <th>CE_uid</th>\n",
       "      <th>CE_game_template_id</th>\n",
       "      <th>CE_mst_advertiser_order_id</th>\n",
       "      <th>CE_mst_user_type_id</th>\n",
       "      <th>OH_auction_type_id=1.0</th>\n",
       "      <th>OH_auction_type_id=2.0</th>\n",
       "      <th>OH_auction_type_id=4.0</th>\n",
       "      <th>OH_header_bidding=0.0</th>\n",
       "      <th>OH_header_bidding=1.0</th>\n",
       "      <th>OH_is_interstitial=1.0</th>\n",
       "      <th>OH_is_interstitial=0.0</th>\n",
       "      <th>OH_user_type_id=1</th>\n",
       "      <th>OH_user_type_id=2</th>\n",
       "      <th>OH_user_type_id=4</th>\n",
       "      <th>OH_user_type_id=3</th>\n",
       "      <th>advertiser_id_by_uid</th>\n",
       "      <th>app_id_by_uid</th>\n",
       "      <th>media_app_id_by_uid</th>\n",
       "      <th>campaign_id_by_uid</th>\n",
       "      <th>uid_dayofweek=0</th>\n",
       "      <th>uid_dayofweek=1</th>\n",
       "      <th>uid_dayofweek=2</th>\n",
       "      <th>uid_dayofweek=3</th>\n",
       "      <th>uid_dayofweek=4</th>\n",
       "      <th>uid_dayofweek=5</th>\n",
       "      <th>uid_dayofweek=6</th>\n",
       "      <th>uid_hour_zone=0</th>\n",
       "      <th>uid_hour_zone=1</th>\n",
       "      <th>uid_hour_zone=2</th>\n",
       "      <th>uid_hour_zone=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997590</th>\n",
       "      <td>32994.0</td>\n",
       "      <td>5487.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>108518</td>\n",
       "      <td>1</td>\n",
       "      <td>1347</td>\n",
       "      <td>49</td>\n",
       "      <td>626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017895</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>0.129836</td>\n",
       "      <td>48160</td>\n",
       "      <td>941185</td>\n",
       "      <td>856650</td>\n",
       "      <td>2205632</td>\n",
       "      <td>362</td>\n",
       "      <td>9</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>48160</td>\n",
       "      <td>73640</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997591</th>\n",
       "      <td>984500.0</td>\n",
       "      <td>116145.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20034.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57111321.0</td>\n",
       "      <td>876350.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107523</td>\n",
       "      <td>1</td>\n",
       "      <td>1347</td>\n",
       "      <td>66</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101821</td>\n",
       "      <td>156196</td>\n",
       "      <td>137281</td>\n",
       "      <td>2205632</td>\n",
       "      <td>759</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101821</td>\n",
       "      <td>641045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997592</th>\n",
       "      <td>38298.0</td>\n",
       "      <td>17147.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>108518</td>\n",
       "      <td>1</td>\n",
       "      <td>1271</td>\n",
       "      <td>47</td>\n",
       "      <td>626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20516</td>\n",
       "      <td>42014</td>\n",
       "      <td>42014</td>\n",
       "      <td>2205632</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>74251.0</td>\n",
       "      <td>20516</td>\n",
       "      <td>852146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997593</th>\n",
       "      <td>651451.0</td>\n",
       "      <td>96344.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19060.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17103589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>108518</td>\n",
       "      <td>1</td>\n",
       "      <td>1347</td>\n",
       "      <td>66</td>\n",
       "      <td>627</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>1679</td>\n",
       "      <td>128697</td>\n",
       "      <td>128697</td>\n",
       "      <td>2205632</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1679</td>\n",
       "      <td>852146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997594</th>\n",
       "      <td>55743.0</td>\n",
       "      <td>42167.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13575.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>108518</td>\n",
       "      <td>1</td>\n",
       "      <td>1274</td>\n",
       "      <td>10</td>\n",
       "      <td>626</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032364</td>\n",
       "      <td>0.032364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20516</td>\n",
       "      <td>13915</td>\n",
       "      <td>1828</td>\n",
       "      <td>2205632</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2882.0</td>\n",
       "      <td>20516</td>\n",
       "      <td>852146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         first_login_interval  max_login_interval  frequency  login_frequency  \\\n",
       "1997590               32994.0              5487.0          1              6.0   \n",
       "1997591              984500.0            116145.0          2              1.0   \n",
       "1997592               38298.0             17147.0          5              1.0   \n",
       "1997593              651451.0             96344.0          0              1.0   \n",
       "1997594               55743.0             42167.0          6              1.0   \n",
       "\n",
       "         last_login_interval  from_click  pos  horizontal_width  \\\n",
       "1997590                651.0           1    1               NaN   \n",
       "1997591              20034.0           1    0            1920.0   \n",
       "1997592              21108.0           1    0               NaN   \n",
       "1997593              19060.0           1    1            1280.0   \n",
       "1997594              13575.0           1    1               NaN   \n",
       "\n",
       "         horizontal_height  vertical_width  vertical_height  \\\n",
       "1997590                NaN             NaN              NaN   \n",
       "1997591             1080.0             NaN              NaN   \n",
       "1997592                NaN             NaN              NaN   \n",
       "1997593              720.0             NaN              NaN   \n",
       "1997594                NaN             NaN              NaN   \n",
       "\n",
       "         horizontal_converted_width  horizontal_converted_height  \\\n",
       "1997590                         NaN                          NaN   \n",
       "1997591                       960.0                        540.0   \n",
       "1997592                         NaN                          NaN   \n",
       "1997593                         NaN                          NaN   \n",
       "1997594                         NaN                          NaN   \n",
       "\n",
       "         vertical_converted_width  vertical_converted_height  duration  \\\n",
       "1997590                       NaN                        NaN       0.0   \n",
       "1997591                       NaN                        NaN       6.0   \n",
       "1997592                       NaN                        NaN       0.0   \n",
       "1997593                       NaN                        NaN      14.0   \n",
       "1997594                       NaN                        NaN       0.0   \n",
       "\n",
       "          file_size  converted_file_size  converted_bitrate  adspot_id  \\\n",
       "1997590         0.0                  0.0                0.0         37   \n",
       "1997591  57111321.0             876350.0          1000000.0         47   \n",
       "1997592         0.0                  0.0                0.0         27   \n",
       "1997593  17103589.0                  0.0                0.0         28   \n",
       "1997594         0.0                  0.0                0.0         24   \n",
       "\n",
       "         adspot_video_format_id  country_code  game_feed_asset_type_id  \\\n",
       "1997590                       2             0                        1   \n",
       "1997591                       2             0                        2   \n",
       "1997592                       0             0                        1   \n",
       "1997593                       3             0                        2   \n",
       "1997594                       0             0                        1   \n",
       "\n",
       "         item_id  os  video_template_id     uid  category_id  game_feed_id  \\\n",
       "1997590        1   1                  6  108518            1          1347   \n",
       "1997591        1   1                  0  107523            1          1347   \n",
       "1997592      893   1                  6  108518            1          1271   \n",
       "1997593        1   0                  6  108518            1          1347   \n",
       "1997594        1   1                  6  108518            1          1274   \n",
       "\n",
       "         game_template_id  horizontal_mst_advertiser_video_id  \\\n",
       "1997590                49                                 626   \n",
       "1997591                66                                 271   \n",
       "1997592                47                                 626   \n",
       "1997593                66                                 627   \n",
       "1997594                10                                 626   \n",
       "\n",
       "         vertical_mst_advertiser_video_id  \\\n",
       "1997590                                 2   \n",
       "1997591                                 2   \n",
       "1997592                                 2   \n",
       "1997593                                 2   \n",
       "1997594                                 2   \n",
       "\n",
       "         horizontal_converted_rectangle_type_id  \\\n",
       "1997590                                       0   \n",
       "1997591                                       1   \n",
       "1997592                                       0   \n",
       "1997593                                       0   \n",
       "1997594                                       0   \n",
       "\n",
       "         vertical_converted_rectangle_type_id  mst_advertiser_id  \\\n",
       "1997590                                     0                 43   \n",
       "1997591                                     0                 28   \n",
       "1997592                                     0                110   \n",
       "1997593                                     0                117   \n",
       "1997594                                     0                110   \n",
       "\n",
       "         mst_advertiser_order_id  mst_user_type_id  hour  hour_zone  \\\n",
       "1997590                       33                 5     8          1   \n",
       "1997591                      101                 3     8          1   \n",
       "1997592                       35                 4     8          1   \n",
       "1997593                      129                 4     8          1   \n",
       "1997594                       35                 4     8          1   \n",
       "\n",
       "         dayofweek  TGE_app_id  TGE_media_app_id  TGE_campaign_id  \\\n",
       "1997590          4    0.017895          0.018655         0.129836   \n",
       "1997591          4    0.027778          0.027778         0.000000   \n",
       "1997592          4    0.000000          0.000000         0.000000   \n",
       "1997593          4    0.022727          0.022727         0.009208   \n",
       "1997594          4    0.032364          0.032364         0.000000   \n",
       "\n",
       "         CE_advertiser_id  CE_adnw_id  CE_adspot_id  CE_category_id  \\\n",
       "1997590             48160      941185        856650         2205632   \n",
       "1997591            101821      156196        137281         2205632   \n",
       "1997592             20516       42014         42014         2205632   \n",
       "1997593              1679      128697        128697         2205632   \n",
       "1997594             20516       13915          1828         2205632   \n",
       "\n",
       "         CE_game_feed_id  CE_uid  CE_game_template_id  \\\n",
       "1997590              362       9               1286.0   \n",
       "1997591              759       2                  NaN   \n",
       "1997592               44       2              74251.0   \n",
       "1997593               14       1                  NaN   \n",
       "1997594               30       2               2882.0   \n",
       "\n",
       "         CE_mst_advertiser_order_id  CE_mst_user_type_id  \\\n",
       "1997590                       48160                73640   \n",
       "1997591                      101821               641045   \n",
       "1997592                       20516               852146   \n",
       "1997593                        1679               852146   \n",
       "1997594                       20516               852146   \n",
       "\n",
       "         OH_auction_type_id=1.0  OH_auction_type_id=2.0  \\\n",
       "1997590                       0                       1   \n",
       "1997591                       1                       0   \n",
       "1997592                       0                       1   \n",
       "1997593                       1                       0   \n",
       "1997594                       1                       0   \n",
       "\n",
       "         OH_auction_type_id=4.0  OH_header_bidding=0.0  OH_header_bidding=1.0  \\\n",
       "1997590                       0                      1                      0   \n",
       "1997591                       0                      1                      0   \n",
       "1997592                       0                      0                      0   \n",
       "1997593                       0                      0                      0   \n",
       "1997594                       0                      0                      0   \n",
       "\n",
       "         OH_is_interstitial=1.0  OH_is_interstitial=0.0  OH_user_type_id=1  \\\n",
       "1997590                       1                       0                  0   \n",
       "1997591                       1                       0                  0   \n",
       "1997592                       0                       1                  0   \n",
       "1997593                       0                       1                  1   \n",
       "1997594                       0                       1                  0   \n",
       "\n",
       "         OH_user_type_id=2  OH_user_type_id=4  OH_user_type_id=3  \\\n",
       "1997590                  1                  0                  0   \n",
       "1997591                  1                  0                  0   \n",
       "1997592                  1                  0                  0   \n",
       "1997593                  0                  0                  0   \n",
       "1997594                  1                  0                  0   \n",
       "\n",
       "         advertiser_id_by_uid  app_id_by_uid  media_app_id_by_uid  \\\n",
       "1997590                     1              1                    1   \n",
       "1997591                     1              2                    2   \n",
       "1997592                     2              1                    1   \n",
       "1997593                     1              1                    1   \n",
       "1997594                     1              0                    0   \n",
       "\n",
       "         campaign_id_by_uid  uid_dayofweek=0  uid_dayofweek=1  \\\n",
       "1997590                   2         0.111111              0.0   \n",
       "1997591                   1         0.000000              0.0   \n",
       "1997592                   2         0.000000              0.0   \n",
       "1997593                   1         0.000000              0.0   \n",
       "1997594                   1         0.000000              0.5   \n",
       "\n",
       "         uid_dayofweek=2  uid_dayofweek=3  uid_dayofweek=4  uid_dayofweek=5  \\\n",
       "1997590              0.0         0.555556         0.111111              0.0   \n",
       "1997591              0.0         0.000000         0.500000              0.5   \n",
       "1997592              0.0         0.500000         0.500000              0.0   \n",
       "1997593              0.0         0.000000         1.000000              0.0   \n",
       "1997594              0.0         0.000000         0.500000              0.0   \n",
       "\n",
       "         uid_dayofweek=6  uid_hour_zone=0  uid_hour_zone=1  uid_hour_zone=2  \\\n",
       "1997590         0.222222         0.111111         0.555556         0.111111   \n",
       "1997591         0.000000         0.000000         1.000000         0.000000   \n",
       "1997592         0.000000         0.000000         0.500000         0.500000   \n",
       "1997593         0.000000         0.000000         1.000000         0.000000   \n",
       "1997594         0.000000         0.000000         0.500000         0.000000   \n",
       "\n",
       "         uid_hour_zone=3  \n",
       "1997590         0.222222  \n",
       "1997591         0.000000  \n",
       "1997592         0.000000  \n",
       "1997593         0.000000  \n",
       "1997594         0.500000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_df.to_feather('../input/train_feat_df.f')\n",
    "test_feat_df.to_feather('../input/test_feat_df.f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(y_pred, y_true):\n",
    "    \"\"\"lightGBM の round ごとに PR-AUC を計算する用\"\"\"\n",
    "    score = average_precision_score(y_true.get_label(), y_pred)\n",
    "    return \"pr_auc\", score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param = {\n",
    "    'objective' : 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed' : 0,\n",
    "    'learning_rate':  0.1,\n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 6.419345380049121e-07, \n",
    "    'lambda_l2': 8.432801302426078, \n",
    "    'num_leaves': 212, \n",
    "    'feature_fraction': 0.4, \n",
    "    'bagging_fraction': 0.9907178796872467, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X, y, cv, params: dict, verbose=100):\n",
    "\n",
    "    models = []\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    # float にしないと悲しい事件が起こるのでそこだけ注意\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        # この部分が交差検証のところです。データセットを cv instance によって分割します\n",
    "        # training data を trian/valid に分割\n",
    "        x_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "        x_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "        \n",
    "        lgbm_train = lgbm.Dataset(x_train, y_train)\n",
    "        lgbm_eval = lgbm.Dataset(x_valid, y_valid, reference=lgbm_train)\n",
    "        \n",
    "        lgbm_model = lgbm.train(params, \n",
    "                                                    lgbm_train, \n",
    "                                                    valid_sets=lgbm_eval,\n",
    "                                                    num_boost_round=1000,\n",
    "                                                    early_stopping_rounds=verbose,\n",
    "                                                    feval=pr_auc,\n",
    "                                                    verbose_eval=verbose)\n",
    "        y_pred = lgbm_model.predict(x_valid, num_iteration=lgbm_model.best_iteration)\n",
    "        \n",
    "        oof_pred[idx_valid] = y_pred\n",
    "        models.append(lgbm_model)\n",
    "\n",
    "        print(f'Fold {i} PR-AUC: {average_precision_score(y_valid, y_pred):.4f}')\n",
    "\n",
    "    score = average_precision_score(y, oof_pred)\n",
    "    print('FINISHED \\ whole score: {:.4f}'.format(score))\n",
    "    return oof_pred, models, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_lgbm(X, y, cv, params, verbose=100):\n",
    "    idx_train, idx_valid = cv[0]\n",
    "    x_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    x_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    lgbm_train = lgbm.Dataset(x_train, y_train)\n",
    "    lgbm_eval = lgbm.Dataset(x_valid, y_valid, reference=lgbm_train)\n",
    "    \n",
    "    best_params, tuning_history = dict(), list()\n",
    "    best = lgbm.train(params,\n",
    "                                  lgbm_train,\n",
    "                                  valid_sets=lgbm_eval,\n",
    "                                  num_boost_round=1000,\n",
    "                                  early_stopping_rounds=verbose,\n",
    "                                  feval=pr_auc,\n",
    "                                  verbose_eval=0)\n",
    "    print('Best Params:', best.params)\n",
    "    print('Best Iteration:', best.best_iteration)\n",
    "    print('Best Score:', best.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if is_time_series:\n",
    "#     fold = TimeSeriesSplit(n_splits=5)\n",
    "# else:\n",
    "#     fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# cv = list(fold.split(train_feat_df, y)) \n",
    "\n",
    "# tuning_lgbm(train_feat_df, y, cv, params=lgbm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lgbm(X, y):\n",
    "    if is_time_series:\n",
    "        fold = TimeSeriesSplit(n_splits=5)\n",
    "    else:\n",
    "        fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    cv = list(fold.split(X, y)) \n",
    "\n",
    "    oof, models, score = train_lgbm(X, y, cv, params=lgbm_param)\n",
    "    return oof, models, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pred():\n",
    "    oof, models, score = kfold_lgbm(train_feat_df, y)\n",
    "    pred_list = []\n",
    "    for model in models:\n",
    "            pred = model.predict(test_feat_df, num_iteration = model.best_iteration)\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "    pred = np.mean(pred_list, axis=0)\n",
    "    return pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def resampling_train_pred():\n",
    "    print(y.value_counts())\n",
    "    negative = y.value_counts()[0]\n",
    "    positive = y.value_counts()[1]\n",
    "    strategy = {0:int(negative/5), 1:positive}\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for i in range(3):\n",
    "        rus = RandomUnderSampler(random_state=i*9, sampling_strategy = strategy)\n",
    "        X_resampled, y_resampled = rus.fit_resample(train_feat_df, y)\n",
    "\n",
    "        oof, models, score = kfold_lgbm(X_resampled, y_resampled)\n",
    "        score_list.append(score)\n",
    "\n",
    "        for model in models:\n",
    "            pred = model.predict(test_feat_df, num_iteration = model.best_iteration)\n",
    "            pred_list.append(pred)\n",
    "\n",
    "        print('----------------[{}]----------------'.format(i))\n",
    "\n",
    "    pred = np.mean(pred_list, axis=0)\n",
    "    score_ave = np.mean(score_list, axis=0)\n",
    "    return pred, score_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp(model):\n",
    "    fi = model.feature_importance()\n",
    "    fn = model.feature_name()\n",
    "    df_feature_importance = pd.DataFrame({'name':fn, 'imp':fi})\n",
    "    df_feature_importance.sort_values('imp', inplace=True)\n",
    "    return df_feature_importance\n",
    "\n",
    "def feature_importance(models):\n",
    "    fi = pd.DataFrame(columns=['name'])\n",
    "    for i, model in enumerate(models):\n",
    "        fi_tmp = feat_imp(model)\n",
    "        colname = 'imp_{}'.format(i)\n",
    "        fi_tmp.rename(columns={'imp': colname}, inplace=True)\n",
    "        fi = pd.merge(fi, fi_tmp, on=['name'], how='outer')\n",
    "    fi['sum'] = fi.sum(axis=1)\n",
    "    return fi.sort_values(['sum'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance(models).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6565\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0966012\tvalid_0's pr_auc: 0.322751\n",
      "[200]\tvalid_0's binary_logloss: 0.0960754\tvalid_0's pr_auc: 0.325878\n",
      "[300]\tvalid_0's binary_logloss: 0.0960983\tvalid_0's pr_auc: 0.325687\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's binary_logloss: 0.0960366\tvalid_0's pr_auc: 0.326245\n",
      "Fold 0 PR-AUC: 0.3262\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6554\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.095779\tvalid_0's pr_auc: 0.325751\n",
      "[200]\tvalid_0's binary_logloss: 0.095338\tvalid_0's pr_auc: 0.329257\n",
      "[300]\tvalid_0's binary_logloss: 0.0953131\tvalid_0's pr_auc: 0.329414\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's binary_logloss: 0.0952857\tvalid_0's pr_auc: 0.329687\n",
      "Fold 1 PR-AUC: 0.3297\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6562\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0953486\tvalid_0's pr_auc: 0.327117\n",
      "[200]\tvalid_0's binary_logloss: 0.0948469\tvalid_0's pr_auc: 0.331107\n",
      "[300]\tvalid_0's binary_logloss: 0.0947792\tvalid_0's pr_auc: 0.331434\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.0947911\tvalid_0's pr_auc: 0.331742\n",
      "Fold 2 PR-AUC: 0.3317\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6575\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0963108\tvalid_0's pr_auc: 0.324041\n",
      "[200]\tvalid_0's binary_logloss: 0.0957868\tvalid_0's pr_auc: 0.327723\n",
      "[300]\tvalid_0's binary_logloss: 0.0957629\tvalid_0's pr_auc: 0.32724\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.0957533\tvalid_0's pr_auc: 0.327981\n",
      "Fold 3 PR-AUC: 0.3280\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6545\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.096922\tvalid_0's pr_auc: 0.316101\n",
      "[200]\tvalid_0's binary_logloss: 0.0963835\tvalid_0's pr_auc: 0.32094\n",
      "[300]\tvalid_0's binary_logloss: 0.0963711\tvalid_0's pr_auc: 0.320685\n",
      "[400]\tvalid_0's binary_logloss: 0.0964238\tvalid_0's pr_auc: 0.32056\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's binary_logloss: 0.0963329\tvalid_0's pr_auc: 0.321431\n",
      "Fold 4 PR-AUC: 0.3214\n",
      "FINISHED \\ whole score: 0.3273\n",
      "CPU times: user 3h 27min 35s, sys: 3min 31s, total: 3h 31min 6s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred, score = train_pred()\n",
    "# pred, score = resampling_train_pred():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred) == len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_time_series:\n",
    "    out_filename = 'submission_ts.csv'\n",
    "else:\n",
    "    out_filename = 'submission.csv'\n",
    "    \n",
    "sub_df = pd.DataFrame({ 'target': pred })\n",
    "sub_df.to_csv(os.path.join(OUTPUT_DIR, out_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- feature=78\n",
      "- score=0.3273\n"
     ]
    }
   ],
   "source": [
    "print('- feature={}'.format(feature_count))\n",
    "print('- score={:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_ensumble:\n",
    "    sub = pd.read_csv('../output/submission.csv')\n",
    "    sub_ts = pd.read_csv('../output/submission_ts.csv')\n",
    "    assert len(sub) == len(sub_ts)\n",
    "    sub['target'] = (sub['target'] + sub_ts['target'])/2\n",
    "    sub.to_csv('../output/ensumble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple_28: login_interval, frequency関係の特徴量追加\n",
    "- feature=85\n",
    "- score=0.3298\n",
    "- publicLB= 0.2369\n",
    "\n",
    "#### simple_27: pivot('dayofweek', 'hour_zone')\n",
    "- feature=78\n",
    "- score=0.3273\n",
    "- publicLB= 0.2420\n",
    "\n",
    "#### simple_26: CE('mst_advertiser_order_id', 'mst_user_type_id',)\n",
    "- feature=67\n",
    "- score=0.3179\n",
    "- publicLB= 0.24\n",
    "\n",
    "#### simple_25: LE->TGE('mst_advertiser_order_id', 'mst_user_type_id',)\n",
    "- feature=65\n",
    "- score=0.3088\n",
    "- publicLB= 0.237\n",
    "\n",
    "#### simple_24: マージを先にしてIDをLE\n",
    "- feature=65\n",
    "- score=0.3160\n",
    "- publicLB= 0.2409 ★best★\n",
    "\n",
    "#### ensumble_23: simple19 + ts23\n",
    "- publicLB= 0.2395 ★best★\n",
    "\n",
    "#### ts_23: 19相当に戻す, TimeSeriesCV(5)\n",
    "- feature=61\n",
    "- score=0.2222\n",
    "- publicLB= 0.2345\n",
    "\n",
    "#### simple_22: CEをKFlod(5), TGEをTimeSeriesSplit(5)\n",
    "- feature=61\n",
    "- score=0.3100\n",
    "- publicLB= 0.2113\n",
    "\n",
    "#### simple_21: CEをTimeSeriesSplit(10)に, NaNは平均\n",
    "- feature=61\n",
    "- score=0.2713\n",
    "- publicLB= 0.2216\n",
    "\n",
    "#### simple_20: TGEをの欠損をNaNに\n",
    "- feature=61\n",
    "- score=0.3153\n",
    "- publicLB= 0.2374\n",
    "\n",
    "#### simple_19: TGEをTimeSeriesSplit(10)に\n",
    "- feature=61\n",
    "- score=0.3153\n",
    "- publicLB= 0.2384\n",
    "\n",
    "#### simple_18: agg(unique系)\n",
    "- feature=61\n",
    "- score=0.3127\n",
    "- publicLB= 0.2337\n",
    "\n",
    "#### simple_17: \n",
    "##### CE(+'advertiser_id'), TGE(-'advertiser_id')\n",
    "- feature=57\n",
    "- score=0.3015\n",
    "- publicLB= 0.2322\n",
    "\n",
    "#### simple_16: \n",
    "##### CE(+'uid')\n",
    "- feature=57\n",
    "- score=0.3024\n",
    "- publicLB= 0.2346\n",
    "\n",
    "##### cont(+'adnw_id',)\n",
    "- feature=57\n",
    "- score=0.2470\n",
    "\n",
    "##### cont(+'adnw_id',), CE(+'uid')\n",
    "- feature=58\n",
    "- score=0.3021\n",
    "\n",
    "##### cont(+'adnw_id',), CE(+'uid', -'game_template_id')\n",
    "- feature=57\n",
    "- score=0.3019\n",
    "\n",
    "##### CE('adnw_id',)\n",
    "- feature=57\n",
    "- score=0.2476\n",
    "\n",
    "#### simple_15: \n",
    "- LE ('adspot_id', 'uid')\n",
    "- feature=56\n",
    "- score=0.2468\n",
    "- publicLB= 0.2195\n",
    "\n",
    "#### simple_14: \n",
    "- TGE->LE (\"category_id\", \"game_feed_id\", \"game_template_id\")\n",
    "- feature=54\n",
    "- score=0.2419\n",
    "- publicLB= 0.2171\n",
    "\n",
    "#### simple_13:\n",
    "##### 8-3 相当に戻す\n",
    "- feature=45\n",
    "- score=0.2484\n",
    "##### CE追加  'adnw_id', 'adspot_id', 'category_id', 'game_feed_id'\n",
    "- feature=46\n",
    "- score=0.2437\n",
    "##### OHE追加 'auction_type_id', 'header_bidding', 'is_interstitial', 'user_type_id'\n",
    "- feature=53\n",
    "- score=0.2431\n",
    "##### CE追加 'game_template_id',\n",
    "- feature=54\n",
    "- score=0.2432\n",
    "- publicLB= 0.2141\n",
    "\n",
    "#### simple_12: 集約系・四則演算全部抜き\n",
    "- Wall time: 6min 20s (SSD)\n",
    "- feature=58\n",
    "- score=0.3025\n",
    "- publicLB= 0.2354 ★best★\n",
    "\n",
    "#### simple_11: count_enc全部抜き\n",
    "- Wall time: 13min 12s\n",
    "- feature=76\n",
    "- score=0.3060\n",
    "- publicLB= 0.2306\n",
    "\n",
    "#### simple_10: total_minute, day, CE_app_id, CE_advertiser_id抜く、\n",
    "- Wall time: 11min 39s\n",
    "- feature=81\n",
    "- score=0.3185\n",
    "- publicLB= 0.2335\n",
    "\n",
    "#### simple_9: 8-1, count, one-hot, aggregate, operation\n",
    "- Wall time: 10min 48s\n",
    "- feature=86\n",
    "- score=0.3284\n",
    "- publicLB= 0.2313\n",
    "\n",
    "#### simple_8-3: label->target : 'game_feed_id', 'game_template_id'\n",
    "- feature=46\n",
    "- score=0.2490\n",
    "- publicLB= 0.2183\n",
    "\n",
    "#### simple_8-2: label->target : category_id\n",
    "- feature=46\n",
    "- score=0.2492\n",
    "\n",
    "#### simple_8-1: label->target : campaign_id\n",
    "- feature=46\n",
    "- score=0.2495\n",
    "\n",
    "#### simple_7: 追加のtarget_encを抜いた\n",
    "- Wall time: 7min 21s (vCPU x 24、メモリ 96 GB)\n",
    "- feature=46\n",
    "- score=0.2486\n",
    "- publicLB= 0.2207\n",
    "\n",
    "#### simple_6: label_enc + target_enc\n",
    "- Wall time: 3min 56s (vCPU x 24、メモリ 96 GB)\n",
    "- feature=55\n",
    "- score=0.3255\n",
    "- publicLB= 0.1798 (Overfit)\n",
    "\n",
    "#### simple_5: target_enc (oof version)\n",
    "- Wall time: 7min 20s\n",
    "- feature=44\n",
    "- score=0.2383\n",
    "- publicLB= 0.2123\n",
    "\n",
    "#### simple_4: target_enc\n",
    "- Wall time: 8min\n",
    "- feature=44\n",
    "- score=0.2589\n",
    "- publicLB= 0.1973 (leak)\n",
    "\n",
    "#### simple_3: tuning\n",
    "- Wall time: 7min 19s\n",
    "- feature=41\n",
    "- score=0.2229\n",
    "- publicLB= 0.1970\n",
    "\n",
    "#### simple_2\n",
    "- Wall time: 47min 46s\n",
    "- feature= 41\n",
    "- score= 0.214588\n",
    "- publicLB= 0.1907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning\n",
    "```\n",
    "Best Params: {\n",
    "    'objective': 'binary', \n",
    "    'boosting_type': 'gbdt', \n",
    "    'seed': 0, \n",
    "    'learning_rate': 0.1, \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 6.419345380049121e-07, \n",
    "    'lambda_l2': 8.432801302426078, \n",
    "    'num_leaves': 212, \n",
    "    'feature_fraction': 0.4, \n",
    "    'bagging_fraction': 0.9907178796872467, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 100, \n",
    "    'num_iterations': 1000, \n",
    "    'early_stopping_round': 100\n",
    "}\n",
    "Best Iteration: 245\n",
    "Best Score: 'pr_auc', 0.22382995580267329\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
