{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgbm\n",
    "# import optuna.integration.lightgbm as lgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import average_precision_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "pd.set_option('display.max_Columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_No = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_time_series = False\n",
    "is_subsample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../input/'\n",
    "OUTPUT_DIR = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df (1997595, 35)\n",
      "test_df (390095, 30)\n",
      "train_feat_df (1997595, 78)\n",
      "test_feat_df (390095, 78)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_feather('../input/train.f')\n",
    "test_df = pd.read_feather('../input/test.f')\n",
    "print('train_df', train_df.shape)\n",
    "print('test_df', test_df.shape)\n",
    "\n",
    "train_feat_df = pd.read_feather('../input/train_feat_df_{}.f'.format(preprocess_No))\n",
    "test_feat_df = pd.read_feather('../input/test_feat_df_{}.f'.format(preprocess_No))\n",
    "print('train_feat_df', train_feat_df.shape)\n",
    "print('test_feat_df', test_feat_df.shape)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "feature_count = len(train_feat_df.columns)\n",
    "print(feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(y_pred, y_true):\n",
    "    \"\"\"lightGBM の round ごとに PR-AUC を計算する用\"\"\"\n",
    "    score = average_precision_score(y_true.get_label(), y_pred)\n",
    "    return \"pr_auc\", score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param = {\n",
    "    'objective' : 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed' : 0,\n",
    "    'learning_rate':  0.01,\n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 6.419345380049121e-07, \n",
    "    'lambda_l2': 8.432801302426078, \n",
    "    'num_leaves': 212, \n",
    "    'feature_fraction': 0.4, \n",
    "    'bagging_fraction': 0.9907178796872467, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(X, y, cv, params: dict, verbose=100):\n",
    "\n",
    "    models = []\n",
    "    # training data の target と同じだけのゼロ配列を用意\n",
    "    # float にしないと悲しい事件が起こるのでそこだけ注意\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv): \n",
    "        # この部分が交差検証のところです。データセットを cv instance によって分割します\n",
    "        # training data を trian/valid に分割\n",
    "        x_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "        x_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "        \n",
    "        lgbm_train = lgbm.Dataset(x_train, y_train)\n",
    "        lgbm_eval = lgbm.Dataset(x_valid, y_valid, reference=lgbm_train)\n",
    "        \n",
    "        lgbm_model = lgbm.train(params, \n",
    "                                                    lgbm_train, \n",
    "                                                    valid_sets=lgbm_eval,\n",
    "                                                    num_boost_round=1000,\n",
    "                                                    early_stopping_rounds=verbose,\n",
    "                                                    feval=pr_auc,\n",
    "                                                    verbose_eval=verbose)\n",
    "        y_pred = lgbm_model.predict(x_valid, num_iteration=lgbm_model.best_iteration)\n",
    "        \n",
    "        oof_pred[idx_valid] = y_pred\n",
    "        models.append(lgbm_model)\n",
    "\n",
    "        print(f'Fold {i} PR-AUC: {average_precision_score(y_valid, y_pred):.4f}')\n",
    "\n",
    "    score = average_precision_score(y, oof_pred)\n",
    "    print('FINISHED \\ whole score: {:.4f}'.format(score))\n",
    "    return oof_pred, models, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_lgbm(X, y, cv, params, verbose=100):\n",
    "    idx_train, idx_valid = cv[0]\n",
    "    x_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    x_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    lgbm_train = lgbm.Dataset(x_train, y_train)\n",
    "    lgbm_eval = lgbm.Dataset(x_valid, y_valid, reference=lgbm_train)\n",
    "    \n",
    "    best_params, tuning_history = dict(), list()\n",
    "    best = lgbm.train(params,\n",
    "                                  lgbm_train,\n",
    "                                  valid_sets=lgbm_eval,\n",
    "                                  num_boost_round=1000,\n",
    "                                  early_stopping_rounds=verbose,\n",
    "                                  feval=pr_auc,\n",
    "                                  verbose_eval=0)\n",
    "    print('Best Params:', best.params)\n",
    "    print('Best Iteration:', best.best_iteration)\n",
    "    print('Best Score:', best.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if is_time_series:\n",
    "#     fold = TimeSeriesSplit(n_splits=5)\n",
    "# else:\n",
    "#     fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# cv = list(fold.split(train_feat_df, y)) \n",
    "\n",
    "# tuning_lgbm(train_feat_df, y, cv, params=lgbm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_lgbm(X, y):\n",
    "    if is_time_series:\n",
    "        fold = TimeSeriesSplit(n_splits=5)\n",
    "    else:\n",
    "        fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    cv = list(fold.split(X, y)) \n",
    "\n",
    "    oof, models, score = train_lgbm(X, y, cv, params=lgbm_param)\n",
    "    return oof, models, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pred():\n",
    "    oof, models, score = kfold_lgbm(train_feat_df, y)\n",
    "    pred_list = []\n",
    "    for model in models:\n",
    "            pred = model.predict(test_feat_df, num_iteration = model.best_iteration)\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "    pred = np.mean(pred_list, axis=0)\n",
    "    return pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def resampling_train_pred():\n",
    "    print(y.value_counts())\n",
    "    negative = y.value_counts()[0]\n",
    "    positive = y.value_counts()[1]\n",
    "    strategy = {0:int(negative/5), 1:positive}\n",
    "\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for i in range(3):\n",
    "        rus = RandomUnderSampler(random_state=i*9, sampling_strategy = strategy)\n",
    "        X_resampled, y_resampled = rus.fit_resample(train_feat_df, y)\n",
    "\n",
    "        oof, models, score = kfold_lgbm(X_resampled, y_resampled)\n",
    "        score_list.append(score)\n",
    "\n",
    "        for model in models:\n",
    "            pred = model.predict(test_feat_df, num_iteration = model.best_iteration)\n",
    "            pred_list.append(pred)\n",
    "\n",
    "        print('----------------[{}] {:.4f}----------------'.format(i, score))\n",
    "\n",
    "    pred = np.mean(pred_list, axis=0)\n",
    "    score_ave = np.mean(score_list, axis=0)\n",
    "    return pred, score_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_imp(model):\n",
    "    fi = model.feature_importance()\n",
    "    fn = model.feature_name()\n",
    "    df_feature_importance = pd.DataFrame({'name':fn, 'imp':fi})\n",
    "    df_feature_importance.sort_values('imp', inplace=True)\n",
    "    return df_feature_importance\n",
    "\n",
    "def feature_importance(models):\n",
    "    fi = pd.DataFrame(columns=['name'])\n",
    "    for i, model in enumerate(models):\n",
    "        fi_tmp = feat_imp(model)\n",
    "        colname = 'imp_{}'.format(i)\n",
    "        fi_tmp.rename(columns={'imp': colname}, inplace=True)\n",
    "        fi = pd.merge(fi, fi_tmp, on=['name'], how='outer')\n",
    "    fi['sum'] = fi.sum(axis=1)\n",
    "    return fi.sort_values(['sum'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance(models).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6565\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.109771\tvalid_0's pr_auc: 0.287751\n",
      "[200]\tvalid_0's binary_logloss: 0.102605\tvalid_0's pr_auc: 0.299688\n",
      "[300]\tvalid_0's binary_logloss: 0.0998966\tvalid_0's pr_auc: 0.307296\n",
      "[400]\tvalid_0's binary_logloss: 0.0986822\tvalid_0's pr_auc: 0.312335\n",
      "[500]\tvalid_0's binary_logloss: 0.0978337\tvalid_0's pr_auc: 0.316664\n",
      "[600]\tvalid_0's binary_logloss: 0.0972783\tvalid_0's pr_auc: 0.320187\n",
      "[700]\tvalid_0's binary_logloss: 0.0969161\tvalid_0's pr_auc: 0.322669\n",
      "[800]\tvalid_0's binary_logloss: 0.0966451\tvalid_0's pr_auc: 0.324531\n",
      "[900]\tvalid_0's binary_logloss: 0.0964275\tvalid_0's pr_auc: 0.326318\n",
      "[1000]\tvalid_0's binary_logloss: 0.0962726\tvalid_0's pr_auc: 0.327594\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0962726\tvalid_0's pr_auc: 0.327594\n",
      "Fold 0 PR-AUC: 0.3276\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6554\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.109389\tvalid_0's pr_auc: 0.291385\n",
      "[200]\tvalid_0's binary_logloss: 0.101962\tvalid_0's pr_auc: 0.303551\n",
      "[300]\tvalid_0's binary_logloss: 0.0990738\tvalid_0's pr_auc: 0.311416\n",
      "[400]\tvalid_0's binary_logloss: 0.0977879\tvalid_0's pr_auc: 0.31664\n",
      "[500]\tvalid_0's binary_logloss: 0.0968937\tvalid_0's pr_auc: 0.32071\n",
      "[600]\tvalid_0's binary_logloss: 0.0963333\tvalid_0's pr_auc: 0.323946\n",
      "[700]\tvalid_0's binary_logloss: 0.0959752\tvalid_0's pr_auc: 0.326239\n",
      "[800]\tvalid_0's binary_logloss: 0.0956907\tvalid_0's pr_auc: 0.328011\n",
      "[900]\tvalid_0's binary_logloss: 0.0954939\tvalid_0's pr_auc: 0.329357\n",
      "[1000]\tvalid_0's binary_logloss: 0.0953423\tvalid_0's pr_auc: 0.330374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0953423\tvalid_0's pr_auc: 0.330374\n",
      "Fold 1 PR-AUC: 0.3304\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6562\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.108997\tvalid_0's pr_auc: 0.293519\n",
      "[200]\tvalid_0's binary_logloss: 0.101551\tvalid_0's pr_auc: 0.305778\n",
      "[300]\tvalid_0's binary_logloss: 0.098679\tvalid_0's pr_auc: 0.313451\n",
      "[400]\tvalid_0's binary_logloss: 0.0974135\tvalid_0's pr_auc: 0.318123\n",
      "[500]\tvalid_0's binary_logloss: 0.0965438\tvalid_0's pr_auc: 0.321913\n",
      "[600]\tvalid_0's binary_logloss: 0.0959996\tvalid_0's pr_auc: 0.325003\n",
      "[700]\tvalid_0's binary_logloss: 0.0956411\tvalid_0's pr_auc: 0.327287\n",
      "[800]\tvalid_0's binary_logloss: 0.0953893\tvalid_0's pr_auc: 0.328899\n",
      "[900]\tvalid_0's binary_logloss: 0.0951815\tvalid_0's pr_auc: 0.330373\n",
      "[1000]\tvalid_0's binary_logloss: 0.0950314\tvalid_0's pr_auc: 0.331518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0950314\tvalid_0's pr_auc: 0.331518\n",
      "Fold 2 PR-AUC: 0.3315\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6575\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.109687\tvalid_0's pr_auc: 0.289614\n",
      "[200]\tvalid_0's binary_logloss: 0.102374\tvalid_0's pr_auc: 0.302473\n",
      "[300]\tvalid_0's binary_logloss: 0.0995688\tvalid_0's pr_auc: 0.310213\n",
      "[400]\tvalid_0's binary_logloss: 0.09833\tvalid_0's pr_auc: 0.315086\n",
      "[500]\tvalid_0's binary_logloss: 0.0974839\tvalid_0's pr_auc: 0.318909\n",
      "[600]\tvalid_0's binary_logloss: 0.096937\tvalid_0's pr_auc: 0.322167\n",
      "[700]\tvalid_0's binary_logloss: 0.0965722\tvalid_0's pr_auc: 0.324584\n",
      "[800]\tvalid_0's binary_logloss: 0.0963066\tvalid_0's pr_auc: 0.326341\n",
      "[900]\tvalid_0's binary_logloss: 0.0961244\tvalid_0's pr_auc: 0.327569\n",
      "[1000]\tvalid_0's binary_logloss: 0.0959899\tvalid_0's pr_auc: 0.328472\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0959899\tvalid_0's pr_auc: 0.328472\n",
      "Fold 3 PR-AUC: 0.3285\n",
      "[LightGBM] [Info] Number of positive: 52392, number of negative: 1545684\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6545\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598076, number of used features: 77\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032784 -> initscore=-3.384468\n",
      "[LightGBM] [Info] Start training from score -3.384468\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.109846\tvalid_0's pr_auc: 0.287304\n",
      "[200]\tvalid_0's binary_logloss: 0.10266\tvalid_0's pr_auc: 0.29846\n",
      "[300]\tvalid_0's binary_logloss: 0.0999273\tvalid_0's pr_auc: 0.305268\n",
      "[400]\tvalid_0's binary_logloss: 0.0987312\tvalid_0's pr_auc: 0.30937\n",
      "[500]\tvalid_0's binary_logloss: 0.0979064\tvalid_0's pr_auc: 0.312851\n",
      "[600]\tvalid_0's binary_logloss: 0.0973872\tvalid_0's pr_auc: 0.315584\n",
      "[700]\tvalid_0's binary_logloss: 0.0970519\tvalid_0's pr_auc: 0.317561\n",
      "[800]\tvalid_0's binary_logloss: 0.0968012\tvalid_0's pr_auc: 0.319057\n",
      "[900]\tvalid_0's binary_logloss: 0.0965914\tvalid_0's pr_auc: 0.320381\n",
      "[1000]\tvalid_0's binary_logloss: 0.0964552\tvalid_0's pr_auc: 0.32123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.0964552\tvalid_0's pr_auc: 0.32123\n",
      "Fold 4 PR-AUC: 0.3212\n",
      "FINISHED \\ whole score: 0.3277\n",
      "CPU times: user 10h 47min 42s, sys: 21min 48s, total: 11h 9min 30s\n",
      "Wall time: 28min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if is_subsample:\n",
    "    pred, score = resampling_train_pred()\n",
    "else:\n",
    "    pred, score = train_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred) == len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "out_filename = 'submission'\n",
    "if is_time_series:\n",
    "    out_filename = out_filename + '_ts'\n",
    "\n",
    "if is_subsample:\n",
    "    out_filename = out_filename + '_sub'\n",
    "\n",
    "sub_df = pd.DataFrame({ 'target': pred })\n",
    "filepath = os.path.join(OUTPUT_DIR, out_filename + '.csv')\n",
    "sub_df.to_csv(filepath, index=False)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- feature=78\n",
      "- score=0.3277\n"
     ]
    }
   ],
   "source": [
    "print('- feature={}'.format(feature_count))\n",
    "print('- score={:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv('../output/submission.csv')\n",
    "# sub_ts = pd.read_csv('../output/submission_ts.csv')\n",
    "# assert len(sub) == len(sub_ts)\n",
    "# sub['target'] = (sub['target'] + sub_ts['target'])/2\n",
    "# sub.to_csv('../output/ensumble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple_30: simple_27相当 learning_rate:0.01\n",
    "- feature=78\n",
    "- score=0.3277\n",
    "- publicLB= 0.2430\n",
    "- privateLB= 0.2599\n",
    "\n",
    "#### subsampling_29: \n",
    "- feature=78\n",
    "- score=0.6501\n",
    "- publicLB= 0.2398\n",
    "- privateLB= 0.2576\n",
    "\n",
    "#### simple_27: pivot('dayofweek', 'hour_zone')\n",
    "- feature=78\n",
    "- score=0.3273\n",
    "- publicLB= 0.2420\n",
    "- privateLB= 0.2582"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning\n",
    "```\n",
    "Best Params: {\n",
    "    'objective': 'binary', \n",
    "    'boosting_type': 'gbdt', \n",
    "    'seed': 0, \n",
    "    'learning_rate': 0.1, \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 6.419345380049121e-07, \n",
    "    'lambda_l2': 8.432801302426078, \n",
    "    'num_leaves': 212, \n",
    "    'feature_fraction': 0.4, \n",
    "    'bagging_fraction': 0.9907178796872467, \n",
    "    'bagging_freq': 2, \n",
    "    'min_child_samples': 100, \n",
    "    'num_iterations': 1000, \n",
    "    'early_stopping_round': 100\n",
    "}\n",
    "Best Iteration: 245\n",
    "Best Score: 'pr_auc', 0.22382995580267329\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
